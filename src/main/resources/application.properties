# Quarkus HTTP port for local testing
quarkus.http.port=8082
%dev.quarkus.http.port=8082
quarkus.http.root-path=/caton

# Required by quarkus-langchain4j-infinispan: the embedding vector dimension used by
# your embeddings model (must be an integer > 0). Adjust to match the model you
# actually use (the project currently includes `langchain4j-embeddings-bge-small-en-q`).
# Example: 1536
quarkus.langchain4j.infinispan.dimension=384
quarkus.langchain4j.gemini.api-key=${GEMINI_API_KEY:000000000000000000000000}
quarkus.langchain4j.gemini.project-id=${GEMINI_PROJECT_ID:000000000000000000000000}
quarkus.langchain4j.gemini.model-name=gemini-1.5-flash
quarkus.langchain4j.gemini.location=us-central1

#use the podman ai lab
#quarkus.langchain4j.openai.base-url=http://localhost:8000/v1
#quarkus.langchain4j.openai.timeout=60s
quarkus.langchain4j.embedding-model.provider=dev.langchain4j.model.embedding.onnx.bgesmallenq.BgeSmallEnQuantizedEmbeddingModel
